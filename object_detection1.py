# -*- coding: utf-8 -*-
"""object detection1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mLCLYyhNPZeob9S9-XxvoidmaZ5u3Cne
"""

!pip install gtts





import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from gtts import gTTS
import os
from IPython.display import Audio
import re

!wget https://pjreddie.com/media/files/yolov3.weights
!wget --no-check-certificate "https://docs.google.com/uc?export=download&id=1rtgmB6aqJf93bcEygGyGPQHRBUg9d03G" -O yolonewcnfg
!wget --no-check-certificate "https://docs.google.com/uc?export=download&id=1NlVRw8EwUkexxsG4j0r3cjX8ShtoFowc" -O ycoconames

model = cv2.dnn.readNet("/content/yolov3.weights","/content/yolonewcnfg")

classes = []
with open("/content/ycoconames","r") as f:
  classes = [line.strip() for line in f.readlines()]
layer_names = model.getLayerNames()
output_layers = [layer_names[i[0] - 1] for i in model.getUnconnectedOutLayers()]
colors = np.random.uniform(0, 255, size=(len(classes), 3))

img = cv2.imread("/content/image 8.jpg")
img = cv2.resize(img, None, fx=0.8, fy=0.8)
height, width, channels = img.shape
cv2_imshow(img)



blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
model.setInput(blob)
outs = model.forward(output_layers)

class_ids = []
confidences = []
boxes = []
for out in outs:
    for detection in out:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]
        if confidence > 0.5:
            # Object detected
            center_x = int(detection[0] * width)
            center_y = int(detection[1] * height)
            w = int(detection[2] * width)
            h = int(detection[3] * height)
            # Rectangle coordinates
            x = int(center_x - w / 2)
            y = int(center_y - h / 2)
            boxes.append([x, y, w, h])
            confidences.append(float(confidence))
            class_ids.append(class_id)



indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)



def generate_text(label,x,y,w,h):
  s = label + " is at the "
  cx = x + w/2
  cy = y + h/2

  if( cx > width/2):
    if(cy > height/2):
      s+="bottom right part of the image "
    else:
      s+="top right part of the image "
  else:
    if(cy>height/2):
      s+="bottom left part of the image "
    else:
      s+="top left part of the image "

  return s



font = cv2.FONT_HERSHEY_PLAIN
text = ""
for i in range(len(boxes)):
    if i in indexes:
        x, y, w, h = boxes[i]
        label = str(classes[class_ids[i]])
        color = colors[i]
        cv2.rectangle(img, (x, y), (x + w, y + h), color, 3)
        cv2.putText(img, label, (x, y + 30), font, 3, color, 2)
        text+=generate_text(label,x,y,w,h)
img = cv2.resize(img, None, fx=0.5, fy=0.5)
cv2_imshow(img)



print(text)



language="en"
obj = gTTS(text,lang=language)



obj.save("audio.mp3")
Audio('audio.mp3',autoplay=True)